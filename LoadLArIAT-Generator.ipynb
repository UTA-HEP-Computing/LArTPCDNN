{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#python DLTools/SetupPython.py > mysetup.py\n",
    "import mysetup\n",
    "from LArTPCDNN.LoadData import *\n",
    "\n",
    "n_threads=1\n",
    "n_threads2=1\n",
    "multiplier=1\n",
    "BatchSize=16\n",
    "FileSearch=\"/data/LArIAT/h5_files/*.h5\"\n",
    "\n",
    "DownSampleSize=8\n",
    "ScanWindowSize=256\n",
    "Normalize=True\n",
    "closefiles=False\n",
    "\n",
    "NSamples=10000\n",
    "EnergyCut=0.61\n",
    "\n",
    "Particles= ['electron', 'antielectron',\n",
    "            'pion',             \n",
    "            'photon',\n",
    "            'pionPlus', 'pionMinus',\n",
    "            'proton', 'antiproton',\n",
    "            'muon', 'antimuon',\n",
    "            'kaonMinus', 'kaonPlus']\n",
    "\n",
    "NClasses=len(Particles)\n",
    "if ScanWindowSize>0:\n",
    "#    shapes=[(BatchSize*multiplier, 2, 240, ScanWindowSize), (BatchSize*multiplier, NClasses)]\n",
    "    shapes=[(BatchSize*multiplier, 240, ScanWindowSize),\n",
    "            (BatchSize*multiplier, 240, ScanWindowSize),\n",
    "            (BatchSize*multiplier, NClasses)]\n",
    "    viewshape=(None, 240, ScanWindowSize)\n",
    "else:\n",
    "    shapes=[(BatchSize*multiplier, 240, 4096/DownSampleSize),\n",
    "            (BatchSize*multiplier, 240, 4096/DownSampleSize),\n",
    "            (BatchSize*multiplier, NClasses)]\n",
    "\n",
    "    viewshape=(None, 240, 4096/DownSampleSize)\n",
    "\n",
    "\n",
    "TrainSampleList,TestSampleList=DivideFiles(FileSearch,[.9,.1],\n",
    "                                           datasetnames=[u'features'],\n",
    "                                           Particles=Particles)\n",
    "\n",
    "def MakeGenerator(SampleList,NSamples,\n",
    "                  cachefile=\"LArIAT-LoadDataTest-Cache.h5\",**kwargs):\n",
    "\n",
    "    return DLMultiClassFilterGenerator(TrainSampleList, FilterEnergy(EnergyCut), max=NSamples,\n",
    "                                       preprocessfunction=ProcessWireData(DownSampleSize,ScanWindowSize,Normalize),\n",
    "                                       postprocessfunction=MergeInputs(),\n",
    "                                       batchsize=BatchSize,\n",
    "                                       shapes=shapes,\n",
    "                                       n_threads=n_threads,\n",
    "                                       multiplier=multiplier,\n",
    "                                       cachefile=cachefile,\n",
    "                                       **kwargs)\n",
    "\n",
    "# Use DLGenerators to read data\n",
    "Train_gen = MakeGenerator(TrainSampleList, NSamples,\n",
    "                            cachefile=\"/tmp/LArTPCDNN-LArIAT-TrainEvent-Cache.h5\")\n",
    "\n",
    "gen=Train_gen.DiskCacheGenerator(n_threads2)\n",
    "\n",
    "Data=gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Data[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('/home/pjsadows/ml/particles/1.1/trained/model_20_epoch67_loss1.65917.h5')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
